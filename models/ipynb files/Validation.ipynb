{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c834228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the model\n",
    "dt = joblib.load('DecisionTree_model.h5')\n",
    "SVM = joblib.load('SVM_model.h5')\n",
    "#NN = load_model('NeuralNetwork_model.h5', compile=False)\n",
    "Logreg = joblib.load('logreg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f6563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mergedvalidation.csv')\n",
    "df.sort_values(by=['HomeTeam'], ascending=True, inplace=True)\n",
    "df.dropna(subset=['FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR'], inplace=True)\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(df[['FTHG','FTAG','HS','AS','HST','AST','HF','AF','HC','AC','HY','AY','HR','AR']])\n",
    "weights = [0.25, 0.15, 0.2, 0.1, 0.1, 0.1, 0.1]\n",
    "home_team_rating = normalized_data[:, [0, 2, 4, 6, 8, 10, 12]].dot(weights)\n",
    "away_team_rating = normalized_data[:, [1, 3, 5, 7, 9, 11, 13]].dot(weights)\n",
    "X = pd.DataFrame({'HomeTeamRating': home_team_rating, 'AwayTeamRating': away_team_rating})\n",
    "y = df['FTR'].apply(lambda x: 1 if x == 'H' else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a445090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Decision Tree): 0.6197368421052631 \n",
      " Precision (Decision Tree): 0.6411960132890365 \n",
      " Recall (Descision Tree): 0.516042780748663 \n",
      " F1-score (Descision Tree): 0.5718518518518518\n",
      "Accuracy (SVM): 0.6421052631578947 \n",
      " Precision (SVM): 0.656441717791411 \n",
      " Recall (SVM): 0.5721925133689839 \n",
      " F1-score (SVM): 0.6114285714285714\n",
      "Accuracy (Logistic Reg): 0.6789473684210526 \n",
      " Precision (Logistic Reg): 0.7044025157232704 \n",
      " Recall (Logistic Reg): 0.5989304812834224 \n",
      " F1-score (Logistic Reg): 0.6473988439306357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gutuw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the validation set for Decision tree\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy1 = accuracy_score(y_test, y_pred)\n",
    "precision1, recall1, f1_score1,_= precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "#make prediction on the validation set for SVM\n",
    "y_pred = SVM.predict(X_test)\n",
    "accuracy2 = accuracy_score(y_test, y_pred)\n",
    "precision2, recall2, f1_score2,_= precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "#make prediction on the validation set for Logistic regression\n",
    "y_pred = Logreg.predict(X_test)\n",
    "accuracy3 = accuracy_score(y_test, y_pred)\n",
    "precision3, recall3, f1_score3,_= precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Accuracy (Decision Tree):\", accuracy1, \"\\n\", \"Precision (Decision Tree):\", precision1 , \"\\n\", \"Recall (Descision Tree):\", recall1, \"\\n\", \"F1-score (Descision Tree):\", f1_score1 )\n",
    "print(\"Accuracy (SVM):\", accuracy2, \"\\n\", \"Precision (SVM):\", precision2 , \"\\n\", \"Recall (SVM):\", recall2, \"\\n\", \"F1-score (SVM):\", f1_score2 )\n",
    "print(\"Accuracy (Logistic Reg):\", accuracy3, \"\\n\", \"Precision (Logistic Reg):\", precision3 ,\"\\n\", \"Recall (Logistic Reg):\", recall3, \"\\n\", \"F1-score (Logistic Reg):\", f1_score3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ba1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HomeTeamRating  AwayTeamRating\n",
      "0          -0.265871        0.414885\n",
      "1           1.452766        0.422443\n",
      "2           0.316712       -0.663916\n",
      "3          -0.025126       -0.084850\n",
      "4           0.460326       -0.781294\n",
      "...              ...             ...\n",
      "3795        0.281330       -0.110667\n",
      "3796       -0.559876       -0.012675\n",
      "3797       -0.820714        1.302073\n",
      "3798       -0.558851       -0.917643\n",
      "3799       -0.020531        0.642986\n",
      "\n",
      "[3800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99125b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
